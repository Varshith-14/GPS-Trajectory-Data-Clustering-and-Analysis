# -*- coding: utf-8 -*-
"""randomforest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_Do4fMLlYOfk-EZFSKjMI-BP5dDe7MhF
"""

import zipfile
import pandas as pd
import datetime
import numpy as np
import re
import folium
import seaborn as sns
from matplotlib import pyplot as plt
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

from sklearn import preprocessing
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import MultiOutputRegressor
from sklearn.metrics import mean_squared_error,r2_score

from google.colab import drive
drive.mount('/content/drive')

zip_file_sample = zipfile.ZipFile(
    "/content/drive/MyDrive/sampleSubmission.csv.zip")
zip_file_train = zipfile.ZipFile(
    "/content/drive/MyDrive/train.csv.zip")
zip_file_test = zipfile.ZipFile(
    "/content/drive/MyDrive/test.csv.zip")
zip_file_GPSlocation = zipfile.ZipFile(
    "/content/drive/MyDrive/metaData_taxistandsID_name_GPSlocation.csv.zip")

sample = pd.read_csv(zip_file_sample.open('sampleSubmission.csv'))
train = pd.read_csv(zip_file_train.open("train.csv"))
test = pd.read_csv(zip_file_test.open("test.csv"))
location = pd.read_csv(zip_file_GPSlocation.open(
    "metaData_taxistandsID_name_GPSlocation.csv"))

sample

train

test

location

train.info()

test.info()

Percent_missing_train = train.isnull().sum() * 100 / len(train)
Percent_missing_train

Percent_missing_test = test.isnull().sum() * 100 / len(train)
Percent_missing_test

train["DAY_TYPE"].unique()

test["DAY_TYPE"].unique()

train = train.drop("DAY_TYPE", axis=1)

test = test.drop("DAY_TYPE", axis=1)

train

test

train.describe()

test.describe()

train.dtypes

test.dtypes

for colum in train:
    unq_vals = np.unique(train[colum])
    nr_vals = len(unq_vals)
    if nr_vals < 10:
        print("The number of unique values for features {} : {} --- {}".format(colum, nr_vals, unq_vals))
    else:
        print("The number of unique values for features {} : {}".format(colum, nr_vals))

for colum in test:
    unq_vals = np.unique(test[colum])
    nr_vals = len(unq_vals)
    if nr_vals < 10:
        print("The number of unique values for features {} : {} --- {}".format(colum, nr_vals, unq_vals))
    else:
        print("The number of unique values for features {} : {}".format(colum, nr_vals))

train["TIMESTAMP"] = [float(time) for time in train["TIMESTAMP"]]
train["data_time"] = [datetime.datetime.fromtimestamp(time, datetime.timezone.utc) for time in train["TIMESTAMP"]]

test["TIMESTAMP"] = [float(time) for time in test["TIMESTAMP"]]
test["data_time"] = [datetime.datetime.fromtimestamp(time, datetime.timezone.utc) for time in test["TIMESTAMP"]]

train["data_time"].value_counts()

test["data_time"].value_counts()

train["year"] = train["data_time"].dt.year
train["month"] = train["data_time"].dt.month
train["week"] = train["data_time"].dt.week
train["day"] = train["data_time"].dt.day
train["hour"] = train["data_time"].dt.hour
train["min"] = train["data_time"].dt.minute
train["weekday"] = train["data_time"].dt.weekday

test["year"] = test["data_time"].dt.year
test["month"] = test["data_time"].dt.month
test["week"] = test["data_time"].dt.week
test["day"] = test["data_time"].dt.day
test["hour"] = test["data_time"].dt.hour
test["min"] = test["data_time"].dt.minute
test["weekday"] = test["data_time"].dt.weekday

encoder = OneHotEncoder(handle_unknown='ignore')

encoder_df = pd.DataFrame(encoder.fit_transform(train[['CALL_TYPE']]).toarray())

final_train = train.join(encoder_df)

final_train.rename(columns={0:'call_type_a', 1:'call_type_b',2:'call_type_c'}, inplace=True)

final_train

encoder = OneHotEncoder(handle_unknown='ignore')

encoder_df = pd.DataFrame(encoder.fit_transform(test[['CALL_TYPE']]).toarray())

final_test = test.join(encoder_df)

final_test.rename(columns={0:'call_type_a', 1:'call_type_b',2:'call_type_c'}, inplace=True)

final_test

lists_1st_lon = []
for i in range(0,len(final_train["POLYLINE"])):
    if final_train["POLYLINE"][i] == '[]':
        k=0
        lists_1st_lon.append(k)
    else:
        k = re.sub(r"[[|[|]|]|]]", "", final_train["POLYLINE"][i]).split(",")[0]
        lists_1st_lon.append(k)

final_train["lon_1st"] = lists_1st_lon

lists_1st_lat = []
for i in range(0,len(final_train["POLYLINE"])):
    if final_train["POLYLINE"][i] == '[]':
        k=0
        lists_1st_lat.append(k)
    else:
        k = re.sub(r"[[|[|]|]|]]", "", final_train["POLYLINE"][i]).split(",")[1]
        lists_1st_lat.append(k)

final_train["lat_1st"] = lists_1st_lat

lists_last_lon = []
for i in range(0,len(final_train["POLYLINE"])):
        if final_train["POLYLINE"][i] == '[]':
            k=0
            lists_last_lon.append(k)
        else:
            k = re.sub(r"[[|[|]|]|]]", "", final_train["POLYLINE"][i]).split(",")[-2]
            lists_last_lon.append(k)

final_train["lon_last"] = lists_last_lon

lists_last_lat = []
for i in range(0,len(final_train["POLYLINE"])):
    if final_train["POLYLINE"][i] == '[]':
        k=0
        lists_last_lat.append(k)
    else:
        k = re.sub(r"[[|[|]|]|]]", "", final_train["POLYLINE"][i]).split(",")[-1]
        lists_last_lat.append(k)

final_train["lat_last"] = lists_last_lat

final_train

train = final_train.query("lon_last != 0")

train["lon_1st"] = [float(k) for k in train["lon_1st"]]
train["lat_1st"] = [float(k) for k in train["lat_1st"]]
train["lon_last"] = [float(k) for k in train["lon_last"]]
train["lat_last"] = [float(k) for k in train["lat_last"]]
train['call_type_a']= [int(k) for k in train["call_type_a"]]
train['call_type_b'] =[int(k) for k in train["call_type_b"]]
train['call_type_c']= [int(k) for k in train["call_type_c"]]

train

lists_1st_lon = []
for i in range(0,len(final_test["POLYLINE"])):
    if final_test["POLYLINE"][i] == '[]':
        k=0
        lists_1st_lon.append(k)
    else:
        k = re.sub(r"[[|[|]|]|]]", "", final_test["POLYLINE"][i]).split(",")[0]
        lists_1st_lon.append(k)

final_test["lon_1st"] = lists_1st_lon

lists_1st_lat = []
for i in range(0,len(final_test["POLYLINE"])):
    if final_test["POLYLINE"][i] == '[]':
        k=0
        lists_1st_lat.append(k)
    else:
        k = re.sub(r"[[|[|]|]|]]", "", final_test["POLYLINE"][i]).split(",")[1]
        lists_1st_lat.append(k)

final_test["lat_1st"] = lists_1st_lat

lists_last_lon = []
for i in range(0,len(final_test["POLYLINE"])):
        if final_test["POLYLINE"][i] == '[]':
            k=0
            lists_last_lon.append(k)
        else:
            k = re.sub(r"[[|[|]|]|]]", "", final_test["POLYLINE"][i]).split(",")[-2]
            lists_last_lon.append(k)

final_test["lon_last"] = lists_last_lon

lists_last_lat = []
for i in range(0,len(final_test["POLYLINE"])):
    if final_test["POLYLINE"][i] == '[]':
        k=0
        lists_last_lat.append(k)
    else:
        k = re.sub(r"[[|[|]|]|]]", "", final_test["POLYLINE"][i]).split(",")[-1]
        lists_last_lat.append(k)

final_test["lat_last"] = lists_last_lat

final_test

test = final_test.query("lon_last != 0")

test["lon_1st"] = [float(k) for k in test["lon_1st"]]
test["lat_1st"] = [float(k) for k in test["lat_1st"]]
test["lon_last"] = [float(k) for k in test["lon_last"]]
test["lat_last"] = [float(k) for k in test["lat_last"]]
test['call_type_a']= [int(k) for k in test["call_type_a"]]
test['call_type_b'] =[int(k) for k in test["call_type_b"]]
test['call_type_c']= [int(k) for k in test["call_type_c"]]

test

year = [2013,2014]

fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,10))
axs = axs.flatten()

colors = ['blue', 'cyan']
for i, year in enumerate(year):
    data2 = train.loc[train.year == year,:]
    sns.distplot(data2.hour, ax=axs[i], color=colors[i%2])
    axs[i].set_title(f'Trip time distribution For Year {year} (Hour in the Day)')

plt.tight_layout()
plt.show()

months = [1,2,3,4,5,6,7,8,9,10,11,12]

fig, axs = plt.subplots(nrows=4, ncols=3, figsize=(20,10))
axs = axs.flatten()

for i, month in enumerate(months):
    data2 = train.loc[train.month == month,:].reset_index(drop = True)
    sns.distplot(data2.hour, ax=axs[i])
    axs[i].set_title(f'Trip time distribution For Month {month} (Hour in the Day)')

plt.tight_layout()
plt.show()

weekday = [0, 1, 2, 3, 4, 5, 6]

fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(20,15))
axs = axs.flatten()

for i, day in enumerate(weekday):
    data2 = train.loc[train.weekday == day,:]
    sns.distplot(data2.hour, ax=axs[i])
    axs[i].set_title(f'Trip time distribution For weekday {day} (Hour in the Day)')

plt.tight_layout()
plt.show()

weekday = pd.DataFrame(data=train.groupby("weekday").TRIP_ID.count()).reset_index()

with plt.style.context("fivethirtyeight"):
    plt.figure(figsize=(10,6))
    plt.plot(weekday["weekday"], weekday["TRIP_ID"])
    plt.xlabel("weekday\n (0:Monday ~ 6:Sunday)")
    plt.ylabel("count")
    plt.ylim([200000, 300000])

countplt, ax = plt.subplots(figsize = (10,7))
ax =sns.countplot(x = train['CALL_TYPE'],data=train,palette='pastel' )
for rect in ax.patches:
    ax.text (rect.get_x() + rect.get_width()  / 2,rect.get_height()+ 0.75,rect.get_height(),horizontalalignment='center', fontsize = 11)

del train['CALL_TYPE']

train['ORIGIN_CALL'] = train[['ORIGIN_CALL']].fillna('')
train['ORIGIN_STAND'] = train[['ORIGIN_STAND']].fillna('')

new_train = train.copy()
new_train

zfig, ax = plt.subplots(figsize=(15,15))
sns.heatmap(new_train.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm',square=True)

mapping_1st = pd.DataFrame({
    "date":train.head(10000)["data_time"].values,
    "lat":train.head(10000)["lat_1st"].values,
    "lon":train.head(10000)["lon_1st"].values
})

mapping_last = pd.DataFrame({
    "date":train.head(10000)["data_time"].values,
    "lat":train.head(10000)["lat_last"].values,
    "lon":train.head(10000)["lon_last"].values
})

por_map = folium.Map(location=[41.141412,-8.590324], tiles='Stamen Terrain', zoom_start=11)

for i, r in mapping_1st.iterrows():
    folium.CircleMarker(location=[r["lat"],r["lon"]], radius=0.5, color="red").add_to(por_map)

for i, r in mapping_last.iterrows():
    folium.CircleMarker(location=[r["lat"],r["lon"]], radius=0.5, color="blue").add_to(por_map)

por_map

train["delta_lon"] = train["lon_last"] - train["lon_1st"]
train["delta_lat"] = train["lat_last"] - train["lat_1st"]

test["delta_lon"] = test["lon_last"] - test["lon_1st"]
test["delta_lat"] = test["lat_last"] - test["lat_1st"]

train

test

ml_train = train.copy()

def origin_call_flg(x):
    if x["ORIGIN_CALL"] == None:
        res = 0
    else:
        res = 1
    return res
ml_train["ORIGIN_CALL"] = ml_train.apply(origin_call_flg, axis=1)

def origin_stand_flg(x):
    if x["ORIGIN_STAND"] == None:
        res = 0
    else:
        res=1
    return res
ml_train["ORIGIN_STAND"] = ml_train.apply(origin_stand_flg, axis=1)

def miss_flg(x):
    if x["MISSING_DATA"] == "False":
        res = 0
    else:
        res = 1
    return res
ml_train["MISSING_DATA"] = ml_train.apply(miss_flg, axis=1)

ml_test = test.copy()
def origin_call_flg(x):
    if x["ORIGIN_CALL"] == None:
        res = 0
    else:
        res = 1
    return res
ml_test["ORIGIN_CALL"] = ml_test.apply(origin_call_flg, axis=1)

def origin_stand_flg(x):
    if x["ORIGIN_STAND"] == None:
        res = 0
    else:
        res=1
    return res
ml_test["ORIGIN_STAND"] = ml_test.apply(origin_stand_flg, axis=1)

def miss_flg(x):
    if x["MISSING_DATA"] == "False":
        res = 0
    else:
        res = 1
    return res
ml_test["MISSING_DATA"] = ml_test.apply(miss_flg, axis=1)

ml_train = ml_train.sample(136000)

X = ml_train[["call_type_a","call_type_b","call_type_c",'ORIGIN_CALL','ORIGIN_STAND', 'MISSING_DATA', 'lon_1st', 'lat_1st', 'delta_lon', 'delta_lat']]

y = ml_train[["lon_last","lat_last"]]

X_Test = ml_test[["call_type_a","call_type_b","call_type_c",'ORIGIN_CALL','ORIGIN_STAND', 'MISSING_DATA', 'lon_1st', 'lat_1st', 'delta_lon', 'delta_lat']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

forest = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=1))

forest = forest.fit(X_train, y_train)
y_train_pred = forest.predict(X_train)
y_test_pred = forest.predict(X_test)

print("MSE train:{}".format(mean_squared_error(y_train, y_train_pred)))
print("MSE test;{}".format(mean_squared_error(y_test, y_test_pred)))
print("R2 score train:{}".format(r2_score(y_train, y_train_pred)))
print("R2 score test:{}".format(r2_score(y_test, y_test_pred)))

y_Test_pred = forest.predict(X_Test)
y_Test_pred[2]

submit_lat = y_Test_pred.T[1]
submit_lon = y_Test_pred.T[0]

submit = pd.DataFrame({"TRIP_ID":test["TRIP_ID"], "LATITUDE":submit_lat, "LONGITUDE":submit_lon})

submit.to_csv('submission.csv', index=False)
sub = pd.read_csv("./submission.csv")
sub.head(50)